{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCxWWWkEELHW_Zoy2rSYpontAVVprI93CY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Langchain practice\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: UserWarning: WARNING! gemini_apikey is not default parameter.\n",
      "                gemini_apikey was transferred to model_kwargs.\n",
      "                Please confirm that gemini_apikey is what you intended.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.6, google_api_key=os.environ[\"GEMINI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of India?\"\n",
    "response = llm.predict(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template and LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of India?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"What is the capital of {country}?\")\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_13328\\2600389558.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain=LLMChain(llm=llm, prompt=prompt_template)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_13328\\2600389558.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"India\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Multiple Chains using simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"],\n",
    "     template=\"Please tell me the capital of the{country}\")\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=[\"capital\"],template=\"Suggest me some amazingplace to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain = LLMChain(llm=llm, prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Historical Landmarks:**\\n\\n* **Red Fort:** A sprawling 17th-century fort complex, a UNESCO World Heritage Site known for its stunning architecture and historical significance.\\n* **India Gate:** A majestic war memorial dedicated to Indian soldiers who lost their lives in World War I.\\n* **Humayun's Tomb:** A stunning Mughal mausoleum renowned for its intricate carvings and symmetrical design.\\n* **Qutub Minar:** A towering minaret and UNESCO World Heritage Site, showcasing Islamic architectural prowess.\\n* **Lodi Gardens:** A serene park featuring ancient tombs, mosques, and a lake.\\n\\n**Cultural Attractions:**\\n\\n* **National Museum:** One of the largest museums in India, housing an extensive collection of art, artifacts, and cultural exhibits.\\n* **National Gallery of Modern Art:** Showcasing a wide range of contemporary and modern Indian art.\\n* **India Habitat Centre:** A cultural complex hosting exhibitions, performances, and workshops.\\n* **Connaught Place:** A bustling commercial hub with historic buildings, shops, and restaurants.\\n* **Hauz Khas Village:** A bohemian neighborhood known for its cafes, boutiques, and art galleries.\\n\\n**Temples and Religious Sites:**\\n\\n* **Akshardham Temple:** A grand Hindu temple complex, featuring intricate carvings, lush gardens, and a musical fountain show.\\n* **Jama Masjid:** One of the largest mosques in India, known for its imposing architecture and serene atmosphere.\\n* **Gurudwara Bangla Sahib:** A Sikh temple renowned for its golden dome and sacred pool.\\n* **ISKCON Temple:** A vibrant Hindu temple dedicated to Lord Krishna, offering spiritual retreats and cultural activities.\\n* **Lotus Temple:** A unique and iconic Bahai temple shaped like a lotus flower.\\n\\n**Other Must-Visit Places:**\\n\\n* **Pragati Maidan:** A vast exhibition center hosting trade fairs, events, and cultural shows.\\n* **Lodhi Colony:** A leafy neighborhood with colonial-era bungalows, art galleries, and trendy restaurants.\\n* **Purana Qila:** An ancient fort believed to be the site of the legendary Indraprastha.\\n* **Rashtrapati Bhavan:** The official residence of the President of India.\\n* **Chandni Chowk:** A historic market street known for its vibrant atmosphere, street food, and traditional shops.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Langchain practice\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.6, google_api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"You are a comedian AI assistant. Provide some funny AI-related punchlines.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Why did the AI cross the road? To get to the other algorithm!\n",
      "- What do you call an AI that's always telling jokes? A pun-isher!\n",
      "- Why did the AI get lost in the data center? Because it couldn't find its way out of the matrix!\n",
      "- What's the difference between an AI and a human? One is programmed to make mistakes, and the other is just human!\n",
      "- Why did the AI get a cold? Because it was caught in a logic loop!\n"
     ]
    }
   ],
   "source": [
    "response=chatllm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "from langchain.prompts import ChatPromptTemplate \n",
    "from langchain_core.output_parsers import BaseOutputParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.split(\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    temperature=0.6,\n",
    "    google_api_key=os.environ[\"GEMINI_API_KEY\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"You are a helpful assistant. When given any input, generate 5 synonyms in a comma-separated list.\\nInput: {text}\"\n",
    "\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", human_template)  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt | chatllm | CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"text\": \"intelligent\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smart', ' clever', ' bright', ' brilliant', ' sharp']\n"
     ]
    }
   ],
   "source": [
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
